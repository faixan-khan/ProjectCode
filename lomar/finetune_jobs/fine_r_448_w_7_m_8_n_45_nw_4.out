| distributed init (rank 3): env://, gpu 3
| distributed init (rank 1): env://, gpu 1
| distributed init (rank 0): env://, gpu 0
| distributed init (rank 2): env://, gpu 2
[18:46:37.439850] job dir: /home/khanff/cvpr23/lomar
[18:46:37.439979] Namespace(aa='rand-m9-mstd0.5-inc1',
accum_iter=4,
batch_size=64,
blr=0.0005,
clip_grad=None,
color_jitter=None,
cutmix=1.0,
cutmix_minmax=None,
data_path='/ibex/ai/reference/CV/ILSVR/classification-localization/data/jpeg',
device='cuda',
dist_backend='nccl',
dist_eval=True,
dist_on_itp=False,
dist_url='env://',
distributed=True,
drop_path=0.1,
epochs=100,
eval=False,
finetune='/ibex/ai/project/c2090/lomar_plus_save/checkpoint/raven448/mae_encoderonly_mask_0.8_neigh_45_wind_7_num_4_epochs_100_r_448/checkpoint-99.pth',
global_pool=True,
gpu=0,
input_size=448,
layer_decay=0.65,
local_rank=0,
log_dir='/ibex/ai/project/c2090/lomar_plus_save/logs/raven448/finetuned_mae_encoderonly_mask_0.8_neigh_45_wind_7_num_4_epoches_100_r_448',
lr=None,
min_lr=1e-06,
mixup=0,
mixup_mode='batch',
mixup_prob=1.0,
mixup_switch_prob=0.5,
model='vit_base_448_patch16',
nb_classes=1000,
num_workers=10,
output_dir='/ibex/ai/project/c2090/lomar_plus_save/checkpoint/raven448/finetuned_mae_encoderonly_mask_0.8_neigh_45_wind_7_num_4_epochs_100_r_448',
pin_mem=True,
rank=0,
recount=1,
remode='pixel',
reprob=0.25,
resplit=False,
resume='',
seed=0,
smoothing=0.1,
start_epoch=0,
warmup_epochs=5,
weight_decay=0.05,
world_size=4)
[18:46:50.302315] Dataset ImageFolder
    Number of datapoints: 1281167
    Root location: /ibex/ai/reference/CV/ILSVR/classification-localization/data/jpeg/train
    StandardTransform
Transform: Compose(
               RandomResizedCropAndInterpolation(size=(448, 448), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)
               RandomHorizontalFlip(p=0.5)
               <timm.data.auto_augment.RandAugment object at 0x2ab0b947f518>
               ToTensor()
               Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
               <timm.data.random_erasing.RandomErasing object at 0x2ab1af649a58>
           )
[18:46:51.501696] Dataset ImageFolder
    Number of datapoints: 50000
    Root location: /ibex/ai/reference/CV/ILSVR/classification-localization/data/jpeg/val
    StandardTransform
Transform: Compose(
               Resize(size=448, interpolation=bicubic, max_size=None, antialias=None)
               CenterCrop(size=(448, 448))
               ToTensor()
               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
           )
[18:46:51.501853] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x2ab1af684400>
[18:46:51.507697] Mixup is activated!
[18:46:52.956723] Load pre-trained checkpoint from: /ibex/ai/project/c2090/lomar_plus_save/checkpoint/raven448/mae_encoderonly_mask_0.8_neigh_45_wind_7_num_4_epochs_100_r_448/checkpoint-99.pth
[18:46:52.985591] _IncompatibleKeys(missing_keys=['head.weight', 'head.bias', 'fc_norm.weight', 'fc_norm.bias'], unexpected_keys=['mask_token', 'norm.weight', 'norm.bias', 'encoder_pred.weight', 'encoder_pred.bias'])
[18:46:53.028071] Model = VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (2): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (3): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (4): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (5): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (6): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (7): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (8): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (9): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (10): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (11): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (head): Linear(in_features=768, out_features=1000, bias=True)
  (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
[18:46:53.028125] number of params (M): 87.02
[18:46:53.028142] base lr: 5.00e-04
[18:46:53.028150] actual lr: 2.00e-03
[18:46:53.028157] accumulate grad iterations: 4
[18:46:53.028163] effective batch size: 1024
[18:46:53.052220] criterion = SoftTargetCrossEntropy()
[18:46:53.052251] Start training for 100 epochs
[18:46:53.052792] log_dir: /ibex/ai/project/c2090/lomar_plus_save/logs/raven448/finetuned_mae_encoderonly_mask_0.8_neigh_45_wind_7_num_4_epoches_100_r_448
[18:47:04.990925] Epoch: [0]  [   0/5004]  eta: 16:35:34  lr: 0.000000  loss: 6.9078 (6.9078)  time: 11.9374  data: 2.1211  max mem: 63228
[18:47:30.351905] Epoch: [0]  [  20/5004]  eta: 2:27:31  lr: 0.000002  loss: 6.9078 (6.9078)  time: 1.2680  data: 0.0002  max mem: 64199
[18:47:54.886128] Epoch: [0]  [  40/5004]  eta: 2:04:46  lr: 0.000003  loss: 6.9077 (6.9078)  time: 1.2267  data: 0.0002  max mem: 64199
[18:48:19.417743] Epoch: [0]  [  60/5004]  eta: 1:56:39  lr: 0.000005  loss: 6.9078 (6.9078)  time: 1.2265  data: 0.0002  max mem: 64199
[18:48:43.920531] Epoch: [0]  [  80/5004]  eta: 1:52:19  lr: 0.000006  loss: 6.9077 (6.9078)  time: 1.2251  data: 0.0002  max mem: 64199
[18:49:08.473701] Epoch: [0]  [ 100/5004]  eta: 1:49:35  lr: 0.000008  loss: 6.9077 (6.9077)  time: 1.2276  data: 0.0002  max mem: 64199
[18:49:33.019086] Epoch: [0]  [ 120/5004]  eta: 1:47:36  lr: 0.000010  loss: 6.9075 (6.9077)  time: 1.2272  data: 0.0002  max mem: 64199
[18:49:57.588040] Epoch: [0]  [ 140/5004]  eta: 1:46:05  lr: 0.000011  loss: 6.9076 (6.9077)  time: 1.2284  data: 0.0002  max mem: 64199
[18:50:22.131481] Epoch: [0]  [ 160/5004]  eta: 1:44:50  lr: 0.000013  loss: 6.9073 (6.9076)  time: 1.2269  data: 0.0002  max mem: 64199
[18:50:46.688615] Epoch: [0]  [ 180/5004]  eta: 1:43:46  lr: 0.000014  loss: 6.9071 (6.9076)  time: 1.2278  data: 0.0002  max mem: 64199
[18:51:11.258225] Epoch: [0]  [ 200/5004]  eta: 1:42:50  lr: 0.000016  loss: 6.9071 (6.9075)  time: 1.2284  data: 0.0002  max mem: 64199
[18:51:35.803472] Epoch: [0]  [ 220/5004]  eta: 1:42:00  lr: 0.000018  loss: 6.9073 (6.9075)  time: 1.2272  data: 0.0002  max mem: 64199
[18:52:00.362544] Epoch: [0]  [ 240/5004]  eta: 1:41:14  lr: 0.000019  loss: 6.9070 (6.9075)  time: 1.2279  data: 0.0002  max mem: 64199
[18:52:24.920338] Epoch: [0]  [ 260/5004]  eta: 1:40:31  lr: 0.000021  loss: 6.9061 (6.9074)  time: 1.2278  data: 0.0002  max mem: 64199
[18:52:49.450014] Epoch: [0]  [ 280/5004]  eta: 1:39:51  lr: 0.000022  loss: 6.9066 (6.9074)  time: 1.2264  data: 0.0002  max mem: 64199
[18:53:14.006259] Epoch: [0]  [ 300/5004]  eta: 1:39:13  lr: 0.000024  loss: 6.9060 (6.9073)  time: 1.2278  data: 0.0002  max mem: 64199
[18:53:38.565780] Epoch: [0]  [ 320/5004]  eta: 1:38:36  lr: 0.000026  loss: 6.9054 (6.9072)  time: 1.2279  data: 0.0002  max mem: 64199
[18:54:03.114801] Epoch: [0]  [ 340/5004]  eta: 1:38:01  lr: 0.000027  loss: 6.9054 (6.9071)  time: 1.2274  data: 0.0002  max mem: 64199
[18:54:27.673723] Epoch: [0]  [ 360/5004]  eta: 1:37:28  lr: 0.000029  loss: 6.9042 (6.9069)  time: 1.2279  data: 0.0002  max mem: 64199
[18:54:52.226611] Epoch: [0]  [ 380/5004]  eta: 1:36:55  lr: 0.000030  loss: 6.9028 (6.9067)  time: 1.2276  data: 0.0002  max mem: 64199
[18:55:16.782521] Epoch: [0]  [ 400/5004]  eta: 1:36:23  lr: 0.000032  loss: 6.9035 (6.9065)  time: 1.2277  data: 0.0002  max mem: 64199
[18:55:41.286595] Epoch: [0]  [ 420/5004]  eta: 1:35:51  lr: 0.000034  loss: 6.9017 (6.9064)  time: 1.2252  data: 0.0002  max mem: 64199
[18:56:05.864388] Epoch: [0]  [ 440/5004]  eta: 1:35:20  lr: 0.000035  loss: 6.8992 (6.9061)  time: 1.2289  data: 0.0002  max mem: 64199
[18:56:30.426481] Epoch: [0]  [ 460/5004]  eta: 1:34:50  lr: 0.000037  loss: 6.8969 (6.9058)  time: 1.2281  data: 0.0001  max mem: 64199
[18:56:54.979770] Epoch: [0]  [ 480/5004]  eta: 1:34:21  lr: 0.000038  loss: 6.8980 (6.9054)  time: 1.2276  data: 0.0001  max mem: 64199
[18:57:19.540335] Epoch: [0]  [ 500/5004]  eta: 1:33:51  lr: 0.000040  loss: 6.8933 (6.9049)  time: 1.2280  data: 0.0001  max mem: 64199
[18:57:44.090222] Epoch: [0]  [ 520/5004]  eta: 1:33:22  lr: 0.000042  loss: 6.8895 (6.9043)  time: 1.2275  data: 0.0001  max mem: 64199
[18:58:08.669554] Epoch: [0]  [ 540/5004]  eta: 1:32:54  lr: 0.000043  loss: 6.8836 (6.9035)  time: 1.2289  data: 0.0001  max mem: 64199
[18:58:33.261013] Epoch: [0]  [ 560/5004]  eta: 1:32:26  lr: 0.000045  loss: 6.8743 (6.9024)  time: 1.2295  data: 0.0002  max mem: 64199
[18:58:57.848769] Epoch: [0]  [ 580/5004]  eta: 1:31:58  lr: 0.000046  loss: 6.8706 (6.9012)  time: 1.2294  data: 0.0001  max mem: 64199
[18:59:22.415384] Epoch: [0]  [ 600/5004]  eta: 1:31:30  lr: 0.000048  loss: 6.8541 (6.8998)  time: 1.2283  data: 0.0001  max mem: 64199
[18:59:46.982789] Epoch: [0]  [ 620/5004]  eta: 1:31:03  lr: 0.000050  loss: 6.8453 (6.8980)  time: 1.2283  data: 0.0001  max mem: 64199
[19:00:11.560514] Epoch: [0]  [ 640/5004]  eta: 1:30:36  lr: 0.000051  loss: 6.8466 (6.8963)  time: 1.2288  data: 0.0001  max mem: 64199
[19:00:36.110302] Epoch: [0]  [ 660/5004]  eta: 1:30:08  lr: 0.000053  loss: 6.8253 (6.8941)  time: 1.2274  data: 0.0002  max mem: 64199
[19:01:00.644025] Epoch: [0]  [ 680/5004]  eta: 1:29:41  lr: 0.000054  loss: 6.8048 (6.8916)  time: 1.2267  data: 0.0002  max mem: 64199
[19:01:25.203725] Epoch: [0]  [ 700/5004]  eta: 1:29:14  lr: 0.000056  loss: 6.7992 (6.8889)  time: 1.2280  data: 0.0001  max mem: 64199
[19:01:49.754679] Epoch: [0]  [ 720/5004]  eta: 1:28:47  lr: 0.000058  loss: 6.7839 (6.8859)  time: 1.2275  data: 0.0002  max mem: 64199
[19:02:14.300789] Epoch: [0]  [ 740/5004]  eta: 1:28:21  lr: 0.000059  loss: 6.7674 (6.8827)  time: 1.2273  data: 0.0002  max mem: 64199
[19:02:38.853833] Epoch: [0]  [ 760/5004]  eta: 1:27:54  lr: 0.000061  loss: 6.7563 (6.8795)  time: 1.2276  data: 0.0002  max mem: 64199
[19:03:03.418016] Epoch: [0]  [ 780/5004]  eta: 1:27:27  lr: 0.000062  loss: 6.7421 (6.8762)  time: 1.2282  data: 0.0001  max mem: 64199
[19:03:27.976829] Epoch: [0]  [ 800/5004]  eta: 1:27:01  lr: 0.000064  loss: 6.7315 (6.8726)  time: 1.2279  data: 0.0002  max mem: 64199
[19:03:52.528679] Epoch: [0]  [ 820/5004]  eta: 1:26:35  lr: 0.000066  loss: 6.7087 (6.8687)  time: 1.2275  data: 0.0002  max mem: 64199
[19:04:17.064162] Epoch: [0]  [ 840/5004]  eta: 1:26:08  lr: 0.000067  loss: 6.7040 (6.8651)  time: 1.2267  data: 0.0002  max mem: 64199
[19:04:41.620634] Epoch: [0]  [ 860/5004]  eta: 1:25:42  lr: 0.000069  loss: 6.6914 (6.8612)  time: 1.2278  data: 0.0008  max mem: 64199
[19:05:06.164081] Epoch: [0]  [ 880/5004]  eta: 1:25:16  lr: 0.000070  loss: 6.6997 (6.8574)  time: 1.2271  data: 0.0001  max mem: 64199
[19:05:30.700443] Epoch: [0]  [ 900/5004]  eta: 1:24:50  lr: 0.000072  loss: 6.6777 (6.8533)  time: 1.2268  data: 0.0002  max mem: 64199
[19:05:55.267176] Epoch: [0]  [ 920/5004]  eta: 1:24:24  lr: 0.000074  loss: 6.6765 (6.8496)  time: 1.2283  data: 0.0002  max mem: 64199
[19:06:19.807856] Epoch: [0]  [ 940/5004]  eta: 1:23:58  lr: 0.000075  loss: 6.6389 (6.8453)  time: 1.2270  data: 0.0001  max mem: 64199
[19:06:44.374828] Epoch: [0]  [ 960/5004]  eta: 1:23:33  lr: 0.000077  loss: 6.6343 (6.8411)  time: 1.2283  data: 0.0002  max mem: 64199
[19:07:08.922512] Epoch: [0]  [ 980/5004]  eta: 1:23:07  lr: 0.000078  loss: 6.6192 (6.8370)  time: 1.2273  data: 0.0002  max mem: 64199
[19:07:33.444282] Epoch: [0]  [1000/5004]  eta: 1:22:41  lr: 0.000080  loss: 6.6176 (6.8327)  time: 1.2260  data: 0.0002  max mem: 64199
[19:07:57.992182] Epoch: [0]  [1020/5004]  eta: 1:22:15  lr: 0.000082  loss: 6.6287 (6.8284)  time: 1.2274  data: 0.0002  max mem: 64199
[19:08:22.530853] Epoch: [0]  [1040/5004]  eta: 1:21:49  lr: 0.000083  loss: 6.6417 (6.8243)  time: 1.2269  data: 0.0002  max mem: 64199
[19:08:47.064498] Epoch: [0]  [1060/5004]  eta: 1:21:24  lr: 0.000085  loss: 6.5933 (6.8201)  time: 1.2266  data: 0.0002  max mem: 64199
[19:09:11.620959] Epoch: [0]  [1080/5004]  eta: 1:20:58  lr: 0.000086  loss: 6.5864 (6.8160)  time: 1.2278  data: 0.0002  max mem: 64199
[19:09:36.185994] Epoch: [0]  [1100/5004]  eta: 1:20:33  lr: 0.000088  loss: 6.5586 (6.8117)  time: 1.2282  data: 0.0002  max mem: 64199
[19:10:00.746753] Epoch: [0]  [1120/5004]  eta: 1:20:07  lr: 0.000090  loss: 6.5739 (6.8077)  time: 1.2280  data: 0.0002  max mem: 64199
[19:10:25.318900] Epoch: [0]  [1140/5004]  eta: 1:19:42  lr: 0.000091  loss: 6.5507 (6.8031)  time: 1.2286  data: 0.0002  max mem: 64199
[19:10:49.881961] Epoch: [0]  [1160/5004]  eta: 1:19:17  lr: 0.000093  loss: 6.5630 (6.7991)  time: 1.2281  data: 0.0002  max mem: 64199
[19:11:14.457366] Epoch: [0]  [1180/5004]  eta: 1:18:51  lr: 0.000094  loss: 6.6124 (6.7961)  time: 1.2287  data: 0.0002  max mem: 64199
[19:11:39.000445] Epoch: [0]  [1200/5004]  eta: 1:18:26  lr: 0.000096  loss: 6.5204 (6.7916)  time: 1.2271  data: 0.0002  max mem: 64199
[19:12:03.557748] Epoch: [0]  [1220/5004]  eta: 1:18:01  lr: 0.000098  loss: 6.5187 (6.7874)  time: 1.2278  data: 0.0002  max mem: 64199
[19:12:28.058131] Epoch: [0]  [1240/5004]  eta: 1:17:35  lr: 0.000099  loss: 6.5469 (6.7835)  time: 1.2250  data: 0.0002  max mem: 64199
[19:12:52.617618] Epoch: [0]  [1260/5004]  eta: 1:17:10  lr: 0.000101  loss: 6.5505 (6.7793)  time: 1.2279  data: 0.0002  max mem: 64199
[19:13:17.163262] Epoch: [0]  [1280/5004]  eta: 1:16:44  lr: 0.000102  loss: 6.5005 (6.7752)  time: 1.2272  data: 0.0002  max mem: 64199
[19:13:41.726736] Epoch: [0]  [1300/5004]  eta: 1:16:19  lr: 0.000104  loss: 6.4830 (6.7708)  time: 1.2281  data: 0.0002  max mem: 64199
[19:14:06.284584] Epoch: [0]  [1320/5004]  eta: 1:15:54  lr: 0.000106  loss: 6.5077 (6.7669)  time: 1.2279  data: 0.0001  max mem: 64199
[19:14:30.864541] Epoch: [0]  [1340/5004]  eta: 1:15:29  lr: 0.000107  loss: 6.5452 (6.7634)  time: 1.2290  data: 0.0001  max mem: 64199
[19:14:55.396059] Epoch: [0]  [1360/5004]  eta: 1:15:04  lr: 0.000109  loss: 6.4514 (6.7587)  time: 1.2265  data: 0.0002  max mem: 64199
[19:15:19.947550] Epoch: [0]  [1380/5004]  eta: 1:14:39  lr: 0.000110  loss: 6.4121 (6.7539)  time: 1.2275  data: 0.0002  max mem: 64199
[19:15:44.490582] Epoch: [0]  [1400/5004]  eta: 1:14:13  lr: 0.000112  loss: 6.5061 (6.7499)  time: 1.2271  data: 0.0002  max mem: 64199
[19:16:09.049277] Epoch: [0]  [1420/5004]  eta: 1:13:48  lr: 0.000114  loss: 6.4381 (6.7454)  time: 1.2279  data: 0.0002  max mem: 64199
[19:16:33.619181] Epoch: [0]  [1440/5004]  eta: 1:13:23  lr: 0.000115  loss: 6.4906 (6.7417)  time: 1.2285  data: 0.0002  max mem: 64199
[19:16:58.164368] Epoch: [0]  [1460/5004]  eta: 1:12:58  lr: 0.000117  loss: 6.3243 (6.7369)  time: 1.2272  data: 0.0002  max mem: 64199
[19:17:22.740864] Epoch: [0]  [1480/5004]  eta: 1:12:33  lr: 0.000118  loss: 6.4779 (6.7331)  time: 1.2288  data: 0.0002  max mem: 64199
[19:17:47.295473] Epoch: [0]  [1500/5004]  eta: 1:12:08  lr: 0.000120  loss: 6.4455 (6.7288)  time: 1.2277  data: 0.0002  max mem: 64199
[19:18:11.817394] Epoch: [0]  [1520/5004]  eta: 1:11:43  lr: 0.000122  loss: 6.3728 (6.7242)  time: 1.2261  data: 0.0001  max mem: 64199
[19:18:36.379419] Epoch: [0]  [1540/5004]  eta: 1:11:18  lr: 0.000123  loss: 6.3845 (6.7200)  time: 1.2281  data: 0.0001  max mem: 64199
[19:19:00.943544] Epoch: [0]  [1560/5004]  eta: 1:10:53  lr: 0.000125  loss: 6.4346 (6.7160)  time: 1.2282  data: 0.0002  max mem: 64199
[19:19:25.484466] Epoch: [0]  [1580/5004]  eta: 1:10:28  lr: 0.000126  loss: 6.3959 (6.7118)  time: 1.2270  data: 0.0001  max mem: 64199
[19:19:50.037059] Epoch: [0]  [1600/5004]  eta: 1:10:03  lr: 0.000128  loss: 6.2518 (6.7067)  time: 1.2276  data: 0.0002  max mem: 64199
[19:20:14.603592] Epoch: [0]  [1620/5004]  eta: 1:09:38  lr: 0.000129  loss: 6.3338 (6.7021)  time: 1.2283  data: 0.0002  max mem: 64199
[19:20:39.186867] Epoch: [0]  [1640/5004]  eta: 1:09:13  lr: 0.000131  loss: 6.4155 (6.6985)  time: 1.2291  data: 0.0001  max mem: 64199
[19:21:03.792328] Epoch: [0]  [1660/5004]  eta: 1:08:48  lr: 0.000133  loss: 6.3571 (6.6939)  time: 1.2302  data: 0.0002  max mem: 64199
[19:21:28.342241] Epoch: [0]  [1680/5004]  eta: 1:08:23  lr: 0.000134  loss: 6.4189 (6.6905)  time: 1.2275  data: 0.0002  max mem: 64199
[19:21:52.911107] Epoch: [0]  [1700/5004]  eta: 1:07:58  lr: 0.000136  loss: 6.2662 (6.6859)  time: 1.2284  data: 0.0002  max mem: 64199
[19:22:17.463862] Epoch: [0]  [1720/5004]  eta: 1:07:33  lr: 0.000137  loss: 6.3483 (6.6819)  time: 1.2276  data: 0.0002  max mem: 64199
[19:22:42.051869] Epoch: [0]  [1740/5004]  eta: 1:07:08  lr: 0.000139  loss: 6.2854 (6.6776)  time: 1.2294  data: 0.0002  max mem: 64199
[19:23:06.630210] Epoch: [0]  [1760/5004]  eta: 1:06:43  lr: 0.000141  loss: 6.2925 (6.6738)  time: 1.2289  data: 0.0001  max mem: 64199
[19:23:31.199097] Epoch: [0]  [1780/5004]  eta: 1:06:18  lr: 0.000142  loss: 6.3696 (6.6700)  time: 1.2284  data: 0.0002  max mem: 64199
[19:23:55.782069] Epoch: [0]  [1800/5004]  eta: 1:05:54  lr: 0.000144  loss: 6.3755 (6.6658)  time: 1.2291  data: 0.0002  max mem: 64199
[19:24:20.367792] Epoch: [0]  [1820/5004]  eta: 1:05:29  lr: 0.000145  loss: 6.3427 (6.6618)  time: 1.2292  data: 0.0001  max mem: 64199
[19:24:44.932303] Epoch: [0]  [1840/5004]  eta: 1:05:04  lr: 0.000147  loss: 6.3610 (6.6581)  time: 1.2282  data: 0.0001  max mem: 64199
[19:25:09.529722] Epoch: [0]  [1860/5004]  eta: 1:04:39  lr: 0.000149  loss: 6.3765 (6.6547)  time: 1.2298  data: 0.0001  max mem: 64199
[19:25:34.101580] Epoch: [0]  [1880/5004]  eta: 1:04:14  lr: 0.000150  loss: 6.3538 (6.6511)  time: 1.2286  data: 0.0001  max mem: 64199
[19:25:58.658126] Epoch: [0]  [1900/5004]  eta: 1:03:49  lr: 0.000152  loss: 6.3448 (6.6476)  time: 1.2278  data: 0.0001  max mem: 64199
[19:26:23.206193] Epoch: [0]  [1920/5004]  eta: 1:03:24  lr: 0.000153  loss: 6.2742 (6.6436)  time: 1.2273  data: 0.0002  max mem: 64199
[19:26:47.773381] Epoch: [0]  [1940/5004]  eta: 1:03:00  lr: 0.000155  loss: 6.2510 (6.6391)  time: 1.2283  data: 0.0002  max mem: 64199
[19:27:12.351926] Epoch: [0]  [1960/5004]  eta: 1:02:35  lr: 0.000157  loss: 6.2315 (6.6351)  time: 1.2289  data: 0.0002  max mem: 64199
[19:27:36.964990] Epoch: [0]  [1980/5004]  eta: 1:02:10  lr: 0.000158  loss: 6.2982 (6.6312)  time: 1.2306  data: 0.0001  max mem: 64199
[19:28:01.556443] Epoch: [0]  [2000/5004]  eta: 1:01:45  lr: 0.000160  loss: 6.1723 (6.6269)  time: 1.2295  data: 0.0002  max mem: 64199
[19:28:26.089422] Epoch: [0]  [2020/5004]  eta: 1:01:20  lr: 0.000161  loss: 6.3568 (6.6234)  time: 1.2266  data: 0.0002  max mem: 64199
[19:28:50.660622] Epoch: [0]  [2040/5004]  eta: 1:00:56  lr: 0.000163  loss: 6.2006 (6.6192)  time: 1.2285  data: 0.0002  max mem: 64199
[19:29:15.253539] Epoch: [0]  [2060/5004]  eta: 1:00:31  lr: 0.000165  loss: 6.2664 (6.6151)  time: 1.2296  data: 0.0002  max mem: 64199
[19:29:39.815905] Epoch: [0]  [2080/5004]  eta: 1:00:06  lr: 0.000166  loss: 6.1719 (6.6109)  time: 1.2281  data: 0.0002  max mem: 64199
[19:30:04.385678] Epoch: [0]  [2100/5004]  eta: 0:59:41  lr: 0.000168  loss: 6.2597 (6.6074)  time: 1.2284  data: 0.0002  max mem: 64199
[19:30:28.940244] Epoch: [0]  [2120/5004]  eta: 0:59:16  lr: 0.000169  loss: 6.1635 (6.6031)  time: 1.2277  data: 0.0002  max mem: 64199
[19:30:53.491089] Epoch: [0]  [2140/5004]  eta: 0:58:51  lr: 0.000171  loss: 6.2164 (6.5991)  time: 1.2275  data: 0.0002  max mem: 64199
[19:31:18.039237] Epoch: [0]  [2160/5004]  eta: 0:58:27  lr: 0.000173  loss: 6.1588 (6.5947)  time: 1.2274  data: 0.0002  max mem: 64199
[19:31:42.606026] Epoch: [0]  [2180/5004]  eta: 0:58:02  lr: 0.000174  loss: 6.1953 (6.5907)  time: 1.2283  data: 0.0001  max mem: 64199
[19:32:07.192265] Epoch: [0]  [2200/5004]  eta: 0:57:37  lr: 0.000176  loss: 6.3113 (6.5875)  time: 1.2293  data: 0.0002  max mem: 64199
[19:32:31.780398] Epoch: [0]  [2220/5004]  eta: 0:57:12  lr: 0.000177  loss: 6.2866 (6.5842)  time: 1.2294  data: 0.0002  max mem: 64199
[19:32:56.317980] Epoch: [0]  [2240/5004]  eta: 0:56:48  lr: 0.000179  loss: 6.2315 (6.5805)  time: 1.2268  data: 0.0002  max mem: 64199
[19:33:20.875757] Epoch: [0]  [2260/5004]  eta: 0:56:23  lr: 0.000181  loss: 6.2022 (6.5768)  time: 1.2278  data: 0.0001  max mem: 64199
[19:33:45.417241] Epoch: [0]  [2280/5004]  eta: 0:55:58  lr: 0.000182  loss: 6.2438 (6.5735)  time: 1.2270  data: 0.0002  max mem: 64199
[19:34:09.980255] Epoch: [0]  [2300/5004]  eta: 0:55:33  lr: 0.000184  loss: 6.0241 (6.5687)  time: 1.2281  data: 0.0002  max mem: 64199
[19:34:34.526162] Epoch: [0]  [2320/5004]  eta: 0:55:08  lr: 0.000185  loss: 6.1925 (6.5654)  time: 1.2273  data: 0.0002  max mem: 64199
[19:34:59.086277] Epoch: [0]  [2340/5004]  eta: 0:54:44  lr: 0.000187  loss: 6.1612 (6.5620)  time: 1.2280  data: 0.0002  max mem: 64199
[19:35:23.615033] Epoch: [0]  [2360/5004]  eta: 0:54:19  lr: 0.000189  loss: 6.1658 (6.5586)  time: 1.2264  data: 0.0001  max mem: 64199
[19:35:48.179685] Epoch: [0]  [2380/5004]  eta: 0:53:54  lr: 0.000190  loss: 6.1491 (6.5546)  time: 1.2282  data: 0.0001  max mem: 64199
[19:36:12.739816] Epoch: [0]  [2400/5004]  eta: 0:53:29  lr: 0.000192  loss: 6.0790 (6.5509)  time: 1.2280  data: 0.0001  max mem: 64199
[19:36:37.255932] Epoch: [0]  [2420/5004]  eta: 0:53:05  lr: 0.000193  loss: 6.2029 (6.5473)  time: 1.2258  data: 0.0001  max mem: 64199
[19:37:01.778496] Epoch: [0]  [2440/5004]  eta: 0:52:40  lr: 0.000195  loss: 6.0923 (6.5434)  time: 1.2261  data: 0.0001  max mem: 64199
[19:37:26.357180] Epoch: [0]  [2460/5004]  eta: 0:52:15  lr: 0.000197  loss: 6.0865 (6.5392)  time: 1.2289  data: 0.0001  max mem: 64199
[19:37:50.903977] Epoch: [0]  [2480/5004]  eta: 0:51:50  lr: 0.000198  loss: 5.9807 (6.5349)  time: 1.2273  data: 0.0002  max mem: 64199
[19:38:15.492758] Epoch: [0]  [2500/5004]  eta: 0:51:26  lr: 0.000200  loss: 5.9814 (6.5309)  time: 1.2294  data: 0.0001  max mem: 64199
[19:38:40.051295] Epoch: [0]  [2520/5004]  eta: 0:51:01  lr: 0.000201  loss: 6.1870 (6.5281)  time: 1.2279  data: 0.0002  max mem: 64199
[19:39:04.629665] Epoch: [0]  [2540/5004]  eta: 0:50:36  lr: 0.000203  loss: 6.1047 (6.5247)  time: 1.2289  data: 0.0002  max mem: 64199
[19:39:29.234017] Epoch: [0]  [2560/5004]  eta: 0:50:11  lr: 0.000205  loss: 6.0513 (6.5212)  time: 1.2302  data: 0.0002  max mem: 64199
[19:39:53.801017] Epoch: [0]  [2580/5004]  eta: 0:49:47  lr: 0.000206  loss: 6.0230 (6.5170)  time: 1.2283  data: 0.0002  max mem: 64199
[19:40:18.359841] Epoch: [0]  [2600/5004]  eta: 0:49:22  lr: 0.000208  loss: 6.0725 (6.5139)  time: 1.2279  data: 0.0002  max mem: 64199
[19:40:42.951281] Epoch: [0]  [2620/5004]  eta: 0:48:57  lr: 0.000209  loss: 6.0782 (6.5105)  time: 1.2295  data: 0.0002  max mem: 64199
[19:41:07.511359] Epoch: [0]  [2640/5004]  eta: 0:48:33  lr: 0.000211  loss: 6.1417 (6.5073)  time: 1.2280  data: 0.0002  max mem: 64199
[19:41:32.047316] Epoch: [0]  [2660/5004]  eta: 0:48:08  lr: 0.000213  loss: 6.0944 (6.5038)  time: 1.2268  data: 0.0002  max mem: 64199
[19:41:56.656846] Epoch: [0]  [2680/5004]  eta: 0:47:43  lr: 0.000214  loss: 6.0664 (6.5003)  time: 1.2304  data: 0.0002  max mem: 64199
[19:42:21.237349] Epoch: [0]  [2700/5004]  eta: 0:47:18  lr: 0.000216  loss: 6.0660 (6.4970)  time: 1.2290  data: 0.0002  max mem: 64199
[19:42:45.845724] Epoch: [0]  [2720/5004]  eta: 0:46:54  lr: 0.000217  loss: 6.0791 (6.4939)  time: 1.2304  data: 0.0001  max mem: 64199
[19:43:10.434426] Epoch: [0]  [2740/5004]  eta: 0:46:29  lr: 0.000219  loss: 5.9790 (6.4898)  time: 1.2294  data: 0.0002  max mem: 64199
[19:43:34.955265] Epoch: [0]  [2760/5004]  eta: 0:46:04  lr: 0.000221  loss: 6.1576 (6.4872)  time: 1.2260  data: 0.0002  max mem: 64199
[19:43:59.493988] Epoch: [0]  [2780/5004]  eta: 0:45:40  lr: 0.000222  loss: 6.0641 (6.4837)  time: 1.2269  data: 0.0002  max mem: 64199
[19:44:24.072893] Epoch: [0]  [2800/5004]  eta: 0:45:15  lr: 0.000224  loss: 6.0651 (6.4798)  time: 1.2289  data: 0.0002  max mem: 64199
[19:44:48.671075] Epoch: [0]  [2820/5004]  eta: 0:44:50  lr: 0.000225  loss: 6.0634 (6.4766)  time: 1.2299  data: 0.0002  max mem: 64199
[19:45:13.234613] Epoch: [0]  [2840/5004]  eta: 0:44:26  lr: 0.000227  loss: 6.0612 (6.4730)  time: 1.2281  data: 0.0002  max mem: 64199
[19:45:37.815873] Epoch: [0]  [2860/5004]  eta: 0:44:01  lr: 0.000229  loss: 6.1967 (6.4706)  time: 1.2290  data: 0.0002  max mem: 64199
[19:46:02.394667] Epoch: [0]  [2880/5004]  eta: 0:43:36  lr: 0.000230  loss: 6.0605 (6.4671)  time: 1.2289  data: 0.0002  max mem: 64199
[19:46:26.999154] Epoch: [0]  [2900/5004]  eta: 0:43:11  lr: 0.000232  loss: 5.9062 (6.4638)  time: 1.2302  data: 0.0002  max mem: 64199
[19:46:51.577203] Epoch: [0]  [2920/5004]  eta: 0:42:47  lr: 0.000233  loss: 6.0237 (6.4605)  time: 1.2289  data: 0.0002  max mem: 64199
[19:47:16.150920] Epoch: [0]  [2940/5004]  eta: 0:42:22  lr: 0.000235  loss: 6.0898 (6.4573)  time: 1.2286  data: 0.0002  max mem: 64199
[19:47:40.677001] Epoch: [0]  [2960/5004]  eta: 0:41:57  lr: 0.000237  loss: 5.9473 (6.4539)  time: 1.2263  data: 0.0002  max mem: 64199
[19:48:05.231864] Epoch: [0]  [2980/5004]  eta: 0:41:33  lr: 0.000238  loss: 6.0577 (6.4512)  time: 1.2277  data: 0.0002  max mem: 64199
[19:48:29.788286] Epoch: [0]  [3000/5004]  eta: 0:41:08  lr: 0.000240  loss: 6.0154 (6.4482)  time: 1.2278  data: 0.0002  max mem: 64199
[19:48:54.381470] Epoch: [0]  [3020/5004]  eta: 0:40:43  lr: 0.000241  loss: 6.0426 (6.4454)  time: 1.2296  data: 0.0001  max mem: 64199
[19:49:18.991877] Epoch: [0]  [3040/5004]  eta: 0:40:19  lr: 0.000243  loss: 6.0458 (6.4427)  time: 1.2305  data: 0.0002  max mem: 64199
[19:49:43.579158] Epoch: [0]  [3060/5004]  eta: 0:39:54  lr: 0.000245  loss: 5.9044 (6.4392)  time: 1.2293  data: 0.0001  max mem: 64199
[19:50:08.162261] Epoch: [0]  [3080/5004]  eta: 0:39:29  lr: 0.000246  loss: 5.8134 (6.4354)  time: 1.2291  data: 0.0001  max mem: 64199
[19:50:32.730573] Epoch: [0]  [3100/5004]  eta: 0:39:05  lr: 0.000248  loss: 5.9125 (6.4318)  time: 1.2284  data: 0.0002  max mem: 64199
[19:50:57.269666] Epoch: [0]  [3120/5004]  eta: 0:38:40  lr: 0.000249  loss: 6.0015 (6.4288)  time: 1.2269  data: 0.0002  max mem: 64199
[19:51:21.842827] Epoch: [0]  [3140/5004]  eta: 0:38:15  lr: 0.000251  loss: 6.0243 (6.4262)  time: 1.2286  data: 0.0002  max mem: 64199
[19:51:46.365840] Epoch: [0]  [3160/5004]  eta: 0:37:51  lr: 0.000253  loss: 6.0792 (6.4236)  time: 1.2261  data: 0.0002  max mem: 64199
[19:52:10.945323] Epoch: [0]  [3180/5004]  eta: 0:37:26  lr: 0.000254  loss: 5.8610 (6.4198)  time: 1.2289  data: 0.0002  max mem: 64199
[19:52:35.523114] Epoch: [0]  [3200/5004]  eta: 0:37:01  lr: 0.000256  loss: 5.8826 (6.4161)  time: 1.2288  data: 0.0002  max mem: 64199
[19:53:00.100213] Epoch: [0]  [3220/5004]  eta: 0:36:37  lr: 0.000257  loss: 5.9125 (6.4125)  time: 1.2288  data: 0.0002  max mem: 64199
[19:53:24.687851] Epoch: [0]  [3240/5004]  eta: 0:36:12  lr: 0.000259  loss: 5.9474 (6.4096)  time: 1.2293  data: 0.0002  max mem: 64199
[19:53:49.203793] Epoch: [0]  [3260/5004]  eta: 0:35:47  lr: 0.000261  loss: 5.9260 (6.4066)  time: 1.2258  data: 0.0002  max mem: 64199
[19:54:13.785134] Epoch: [0]  [3280/5004]  eta: 0:35:23  lr: 0.000262  loss: 5.8560 (6.4031)  time: 1.2290  data: 0.0002  max mem: 64199
[19:54:38.348761] Epoch: [0]  [3300/5004]  eta: 0:34:58  lr: 0.000264  loss: 5.8945 (6.4001)  time: 1.2281  data: 0.0002  max mem: 64199
[19:55:02.904743] Epoch: [0]  [3320/5004]  eta: 0:34:33  lr: 0.000265  loss: 5.8880 (6.3970)  time: 1.2278  data: 0.0002  max mem: 64199
[19:55:27.472656] Epoch: [0]  [3340/5004]  eta: 0:34:09  lr: 0.000267  loss: 5.9469 (6.3940)  time: 1.2284  data: 0.0002  max mem: 64199
[19:55:52.053401] Epoch: [0]  [3360/5004]  eta: 0:33:44  lr: 0.000269  loss: 5.8404 (6.3906)  time: 1.2290  data: 0.0001  max mem: 64199
[19:56:16.618590] Epoch: [0]  [3380/5004]  eta: 0:33:19  lr: 0.000270  loss: 5.8483 (6.3870)  time: 1.2282  data: 0.0001  max mem: 64199
[19:56:41.181909] Epoch: [0]  [3400/5004]  eta: 0:32:55  lr: 0.000272  loss: 6.0052 (6.3846)  time: 1.2281  data: 0.0002  max mem: 64199
[19:57:05.748722] Epoch: [0]  [3420/5004]  eta: 0:32:30  lr: 0.000273  loss: 5.7071 (6.3811)  time: 1.2283  data: 0.0002  max mem: 64199
[19:57:30.281605] Epoch: [0]  [3440/5004]  eta: 0:32:05  lr: 0.000275  loss: 5.7920 (6.3777)  time: 1.2266  data: 0.0002  max mem: 64199
[19:57:54.860682] Epoch: [0]  [3460/5004]  eta: 0:31:41  lr: 0.000277  loss: 5.8850 (6.3745)  time: 1.2289  data: 0.0002  max mem: 64199
[19:58:19.410227] Epoch: [0]  [3480/5004]  eta: 0:31:16  lr: 0.000278  loss: 5.9015 (6.3713)  time: 1.2274  data: 0.0002  max mem: 64199
[19:58:43.987204] Epoch: [0]  [3500/5004]  eta: 0:30:51  lr: 0.000280  loss: 5.8359 (6.3682)  time: 1.2288  data: 0.0002  max mem: 64199
[19:59:08.533277] Epoch: [0]  [3520/5004]  eta: 0:30:27  lr: 0.000281  loss: 6.0006 (6.3658)  time: 1.2273  data: 0.0002  max mem: 64199
[19:59:33.100108] Epoch: [0]  [3540/5004]  eta: 0:30:02  lr: 0.000283  loss: 5.9752 (6.3634)  time: 1.2283  data: 0.0002  max mem: 64199
[19:59:57.659494] Epoch: [0]  [3560/5004]  eta: 0:29:37  lr: 0.000285  loss: 5.7592 (6.3603)  time: 1.2279  data: 0.0002  max mem: 64199
[20:00:22.233505] Epoch: [0]  [3580/5004]  eta: 0:29:13  lr: 0.000286  loss: 5.9874 (6.3578)  time: 1.2287  data: 0.0002  max mem: 64199
[20:00:46.796346] Epoch: [0]  [3600/5004]  eta: 0:28:48  lr: 0.000288  loss: 5.9202 (6.3550)  time: 1.2281  data: 0.0002  max mem: 64199
[20:01:11.369919] Epoch: [0]  [3620/5004]  eta: 0:28:23  lr: 0.000289  loss: 5.8230 (6.3516)  time: 1.2286  data: 0.0001  max mem: 64199
[20:01:35.940361] Epoch: [0]  [3640/5004]  eta: 0:27:59  lr: 0.000291  loss: 5.9198 (6.3489)  time: 1.2285  data: 0.0002  max mem: 64199
[20:02:00.523560] Epoch: [0]  [3660/5004]  eta: 0:27:34  lr: 0.000293  loss: 6.0069 (6.3465)  time: 1.2291  data: 0.0002  max mem: 64199
[20:02:25.059602] Epoch: [0]  [3680/5004]  eta: 0:27:10  lr: 0.000294  loss: 5.8080 (6.3435)  time: 1.2268  data: 0.0002  max mem: 64199
[20:02:49.602887] Epoch: [0]  [3700/5004]  eta: 0:26:45  lr: 0.000296  loss: 5.8556 (6.3408)  time: 1.2271  data: 0.0002  max mem: 64199
[20:03:14.138930] Epoch: [0]  [3720/5004]  eta: 0:26:20  lr: 0.000297  loss: 5.8355 (6.3379)  time: 1.2268  data: 0.0001  max mem: 64199
[20:03:38.698131] Epoch: [0]  [3740/5004]  eta: 0:25:56  lr: 0.000299  loss: 5.8688 (6.3351)  time: 1.2279  data: 0.0001  max mem: 64199
[20:04:03.274783] Epoch: [0]  [3760/5004]  eta: 0:25:31  lr: 0.000301  loss: 5.8638 (6.3323)  time: 1.2288  data: 0.0001  max mem: 64199
[20:04:27.848845] Epoch: [0]  [3780/5004]  eta: 0:25:06  lr: 0.000302  loss: 5.7449 (6.3293)  time: 1.2287  data: 0.0001  max mem: 64199
[20:04:52.436530] Epoch: [0]  [3800/5004]  eta: 0:24:42  lr: 0.000304  loss: 5.7852 (6.3266)  time: 1.2293  data: 0.0001  max mem: 64199
[20:05:16.974278] Epoch: [0]  [3820/5004]  eta: 0:24:17  lr: 0.000305  loss: 5.9143 (6.3238)  time: 1.2268  data: 0.0002  max mem: 64199
[20:05:41.521880] Epoch: [0]  [3840/5004]  eta: 0:23:52  lr: 0.000307  loss: 5.6705 (6.3203)  time: 1.2273  data: 0.0002  max mem: 64199
[20:06:06.143510] Epoch: [0]  [3860/5004]  eta: 0:23:28  lr: 0.000309  loss: 5.7781 (6.3176)  time: 1.2310  data: 0.0002  max mem: 64199
[20:06:30.702798] Epoch: [0]  [3880/5004]  eta: 0:23:03  lr: 0.000310  loss: 5.8601 (6.3151)  time: 1.2279  data: 0.0002  max mem: 64199
[20:06:55.307528] Epoch: [0]  [3900/5004]  eta: 0:22:39  lr: 0.000312  loss: 5.7880 (6.3122)  time: 1.2302  data: 0.0001  max mem: 64199
[20:07:19.917199] Epoch: [0]  [3920/5004]  eta: 0:22:14  lr: 0.000313  loss: 5.7462 (6.3092)  time: 1.2304  data: 0.0002  max mem: 64199
[20:07:44.438192] Epoch: [0]  [3940/5004]  eta: 0:21:49  lr: 0.000315  loss: 5.9071 (6.3068)  time: 1.2260  data: 0.0002  max mem: 64199
[20:08:09.011749] Epoch: [0]  [3960/5004]  eta: 0:21:25  lr: 0.000317  loss: 5.7183 (6.3039)  time: 1.2286  data: 0.0002  max mem: 64199
[20:08:33.555901] Epoch: [0]  [3980/5004]  eta: 0:21:00  lr: 0.000318  loss: 5.7476 (6.3006)  time: 1.2272  data: 0.0001  max mem: 64199
[20:08:58.158994] Epoch: [0]  [4000/5004]  eta: 0:20:35  lr: 0.000320  loss: 5.8343 (6.2979)  time: 1.2301  data: 0.0001  max mem: 64199
[20:09:22.697730] Epoch: [0]  [4020/5004]  eta: 0:20:11  lr: 0.000321  loss: 5.6379 (6.2949)  time: 1.2269  data: 0.0002  max mem: 64199
[20:09:47.279414] Epoch: [0]  [4040/5004]  eta: 0:19:46  lr: 0.000323  loss: 5.5985 (6.2917)  time: 1.2290  data: 0.0002  max mem: 64199
[20:10:11.786725] Epoch: [0]  [4060/5004]  eta: 0:19:21  lr: 0.000325  loss: 5.7745 (6.2892)  time: 1.2253  data: 0.0002  max mem: 64199
[20:10:36.325027] Epoch: [0]  [4080/5004]  eta: 0:18:57  lr: 0.000326  loss: 5.9096 (6.2868)  time: 1.2269  data: 0.0002  max mem: 64199
[20:11:00.867012] Epoch: [0]  [4100/5004]  eta: 0:18:32  lr: 0.000328  loss: 5.7479 (6.2841)  time: 1.2271  data: 0.0002  max mem: 64199
[20:11:25.408629] Epoch: [0]  [4120/5004]  eta: 0:18:08  lr: 0.000329  loss: 5.7497 (6.2812)  time: 1.2270  data: 0.0002  max mem: 64199
[20:11:50.010747] Epoch: [0]  [4140/5004]  eta: 0:17:43  lr: 0.000331  loss: 5.7348 (6.2784)  time: 1.2301  data: 0.0001  max mem: 64199
[20:12:14.655774] Epoch: [0]  [4160/5004]  eta: 0:17:18  lr: 0.000333  loss: 5.8631 (6.2761)  time: 1.2322  data: 0.0002  max mem: 64199
[20:12:39.229170] Epoch: [0]  [4180/5004]  eta: 0:16:54  lr: 0.000334  loss: 5.5688 (6.2727)  time: 1.2286  data: 0.0002  max mem: 64199
[20:13:03.795220] Epoch: [0]  [4200/5004]  eta: 0:16:29  lr: 0.000336  loss: 5.9323 (6.2705)  time: 1.2283  data: 0.0002  max mem: 64199
[20:13:28.380178] Epoch: [0]  [4220/5004]  eta: 0:16:04  lr: 0.000337  loss: 5.8601 (6.2686)  time: 1.2292  data: 0.0002  max mem: 64199
[20:13:52.978667] Epoch: [0]  [4240/5004]  eta: 0:15:40  lr: 0.000339  loss: 5.7244 (6.2654)  time: 1.2299  data: 0.0002  max mem: 64199
[20:14:17.557002] Epoch: [0]  [4260/5004]  eta: 0:15:15  lr: 0.000341  loss: 5.7136 (6.2629)  time: 1.2289  data: 0.0002  max mem: 64199
[20:14:42.148183] Epoch: [0]  [4280/5004]  eta: 0:14:51  lr: 0.000342  loss: 5.6681 (6.2602)  time: 1.2295  data: 0.0001  max mem: 64199
[20:15:06.712042] Epoch: [0]  [4300/5004]  eta: 0:14:26  lr: 0.000344  loss: 5.7011 (6.2573)  time: 1.2282  data: 0.0002  max mem: 64199
[20:15:31.291932] Epoch: [0]  [4320/5004]  eta: 0:14:01  lr: 0.000345  loss: 5.5623 (6.2542)  time: 1.2290  data: 0.0002  max mem: 64199
[20:15:55.861651] Epoch: [0]  [4340/5004]  eta: 0:13:37  lr: 0.000347  loss: 5.5554 (6.2506)  time: 1.2284  data: 0.0002  max mem: 64199
[20:16:20.425390] Epoch: [0]  [4360/5004]  eta: 0:13:12  lr: 0.000349  loss: 5.6159 (6.2477)  time: 1.2281  data: 0.0001  max mem: 64199
[20:16:44.999184] Epoch: [0]  [4380/5004]  eta: 0:12:47  lr: 0.000350  loss: 5.7053 (6.2444)  time: 1.2287  data: 0.0001  max mem: 64199
[20:17:09.564483] Epoch: [0]  [4400/5004]  eta: 0:12:23  lr: 0.000352  loss: 5.7678 (6.2422)  time: 1.2282  data: 0.0002  max mem: 64199
[20:17:34.127241] Epoch: [0]  [4420/5004]  eta: 0:11:58  lr: 0.000353  loss: 5.7390 (6.2395)  time: 1.2281  data: 0.0001  max mem: 64199
[20:17:58.666216] Epoch: [0]  [4440/5004]  eta: 0:11:34  lr: 0.000355  loss: 5.6508 (6.2369)  time: 1.2269  data: 0.0001  max mem: 64199
[20:18:23.234128] Epoch: [0]  [4460/5004]  eta: 0:11:09  lr: 0.000357  loss: 5.7790 (6.2348)  time: 1.2283  data: 0.0002  max mem: 64199
[20:18:47.771367] Epoch: [0]  [4480/5004]  eta: 0:10:44  lr: 0.000358  loss: 5.8216 (6.2321)  time: 1.2268  data: 0.0002  max mem: 64199
[20:19:12.280828] Epoch: [0]  [4500/5004]  eta: 0:10:20  lr: 0.000360  loss: 5.6274 (6.2294)  time: 1.2254  data: 0.0002  max mem: 64199
[20:19:36.830958] Epoch: [0]  [4520/5004]  eta: 0:09:55  lr: 0.000361  loss: 5.5940 (6.2264)  time: 1.2275  data: 0.0002  max mem: 64199
[20:20:01.395700] Epoch: [0]  [4540/5004]  eta: 0:09:30  lr: 0.000363  loss: 5.7058 (6.2237)  time: 1.2282  data: 0.0002  max mem: 64199
[20:20:25.940459] Epoch: [0]  [4560/5004]  eta: 0:09:06  lr: 0.000365  loss: 5.7201 (6.2210)  time: 1.2272  data: 0.0002  max mem: 64199
[20:20:50.491580] Epoch: [0]  [4580/5004]  eta: 0:08:41  lr: 0.000366  loss: 5.7113 (6.2188)  time: 1.2275  data: 0.0002  max mem: 64199
[20:21:15.080071] Epoch: [0]  [4600/5004]  eta: 0:08:17  lr: 0.000368  loss: 5.5696 (6.2157)  time: 1.2294  data: 0.0001  max mem: 64199
[20:21:39.650580] Epoch: [0]  [4620/5004]  eta: 0:07:52  lr: 0.000369  loss: 5.6728 (6.2132)  time: 1.2285  data: 0.0001  max mem: 64199
[20:22:04.213171] Epoch: [0]  [4640/5004]  eta: 0:07:27  lr: 0.000371  loss: 5.6522 (6.2107)  time: 1.2281  data: 0.0002  max mem: 64199
[20:22:28.768220] Epoch: [0]  [4660/5004]  eta: 0:07:03  lr: 0.000373  loss: 5.7236 (6.2083)  time: 1.2277  data: 0.0001  max mem: 64199
[20:22:53.362065] Epoch: [0]  [4680/5004]  eta: 0:06:38  lr: 0.000374  loss: 5.7627 (6.2061)  time: 1.2296  data: 0.0002  max mem: 64199
[20:23:17.911952] Epoch: [0]  [4700/5004]  eta: 0:06:14  lr: 0.000376  loss: 5.6016 (6.2033)  time: 1.2275  data: 0.0002  max mem: 64199
[20:23:42.477733] Epoch: [0]  [4720/5004]  eta: 0:05:49  lr: 0.000377  loss: 5.6532 (6.2009)  time: 1.2282  data: 0.0002  max mem: 64199
[20:24:07.029103] Epoch: [0]  [4740/5004]  eta: 0:05:24  lr: 0.000379  loss: 5.8188 (6.1987)  time: 1.2275  data: 0.0002  max mem: 64199
[20:24:31.597987] Epoch: [0]  [4760/5004]  eta: 0:05:00  lr: 0.000380  loss: 5.6633 (6.1964)  time: 1.2284  data: 0.0002  max mem: 64199
[20:24:56.161805] Epoch: [0]  [4780/5004]  eta: 0:04:35  lr: 0.000382  loss: 5.7553 (6.1943)  time: 1.2281  data: 0.0002  max mem: 64199
[20:25:20.697277] Epoch: [0]  [4800/5004]  eta: 0:04:11  lr: 0.000384  loss: 5.5360 (6.1917)  time: 1.2267  data: 0.0002  max mem: 64199
[20:25:45.221969] Epoch: [0]  [4820/5004]  eta: 0:03:46  lr: 0.000385  loss: 5.7443 (6.1898)  time: 1.2262  data: 0.0002  max mem: 64199
[20:26:09.786281] Epoch: [0]  [4840/5004]  eta: 0:03:21  lr: 0.000387  loss: 5.5030 (6.1870)  time: 1.2282  data: 0.0002  max mem: 64199
[20:26:34.356672] Epoch: [0]  [4860/5004]  eta: 0:02:57  lr: 0.000388  loss: 5.7346 (6.1851)  time: 1.2285  data: 0.0002  max mem: 64199
[20:26:58.859969] Epoch: [0]  [4880/5004]  eta: 0:02:32  lr: 0.000390  loss: 5.5128 (6.1823)  time: 1.2251  data: 0.0002  max mem: 64199
[20:27:23.418633] Epoch: [0]  [4900/5004]  eta: 0:02:07  lr: 0.000392  loss: 5.7159 (6.1802)  time: 1.2279  data: 0.0002  max mem: 64199
[20:27:47.952579] Epoch: [0]  [4920/5004]  eta: 0:01:43  lr: 0.000393  loss: 5.1390 (6.1767)  time: 1.2267  data: 0.0002  max mem: 64199
[20:28:12.514503] Epoch: [0]  [4940/5004]  eta: 0:01:18  lr: 0.000395  loss: 5.5708 (6.1740)  time: 1.2281  data: 0.0002  max mem: 64199
[20:28:37.065282] Epoch: [0]  [4960/5004]  eta: 0:00:54  lr: 0.000396  loss: 5.7456 (6.1721)  time: 1.2275  data: 0.0002  max mem: 64199
[20:29:01.585775] Epoch: [0]  [4980/5004]  eta: 0:00:29  lr: 0.000398  loss: 5.7866 (6.1702)  time: 1.2260  data: 0.0002  max mem: 64199
[20:29:25.946435] Epoch: [0]  [5000/5004]  eta: 0:00:04  lr: 0.000400  loss: 5.7882 (6.1684)  time: 1.2180  data: 0.0005  max mem: 64199
[20:29:29.607199] Epoch: [0]  [5003/5004]  eta: 0:00:01  lr: 0.000400  loss: 5.7787 (6.1681)  time: 1.2159  data: 0.0004  max mem: 64199
[20:29:30.112489] Epoch: [0] Total time: 1:42:37 (1.2304 s / it)
[20:29:30.113473] Averaged stats: lr: 0.000400  loss: 5.7787 (6.1694)
[20:29:33.922802] Test:  [  0/196]  eta: 0:09:21  loss: 3.4489 (3.4489)  acc1: 28.1250 (28.1250)  acc5: 56.2500 (56.2500)  time: 2.8661  data: 2.4099  max mem: 64199
[20:29:38.141720] Test:  [ 10/196]  eta: 0:01:59  loss: 3.4489 (3.4653)  acc1: 26.5625 (26.7045)  acc5: 54.6875 (56.9602)  time: 0.6440  data: 0.2192  max mem: 64199
[20:29:42.342754] Test:  [ 20/196]  eta: 0:01:34  loss: 3.4874 (3.4732)  acc1: 28.1250 (28.1994)  acc5: 54.6875 (55.8780)  time: 0.4209  data: 0.0002  max mem: 64199
[20:29:46.551765] Test:  [ 30/196]  eta: 0:01:22  loss: 3.5356 (3.4897)  acc1: 28.1250 (28.0242)  acc5: 54.6875 (55.0907)  time: 0.4204  data: 0.0002  max mem: 64199
[20:29:50.764918] Test:  [ 40/196]  eta: 0:01:14  loss: 3.5408 (3.4962)  acc1: 28.1250 (28.0107)  acc5: 53.1250 (54.4207)  time: 0.4210  data: 0.0002  max mem: 64199
[20:29:54.992102] Test:  [ 50/196]  eta: 0:01:08  loss: 3.5418 (3.5058)  acc1: 28.1250 (27.9105)  acc5: 53.1250 (54.6569)  time: 0.4220  data: 0.0001  max mem: 64199
[20:29:59.218487] Test:  [ 60/196]  eta: 0:01:02  loss: 3.5147 (3.5118)  acc1: 26.5625 (27.8689)  acc5: 54.6875 (54.6619)  time: 0.4226  data: 0.0001  max mem: 64199
[20:30:03.460439] Test:  [ 70/196]  eta: 0:00:57  loss: 3.4288 (3.5037)  acc1: 28.1250 (28.3671)  acc5: 56.2500 (55.0836)  time: 0.4233  data: 0.0011  max mem: 64199
[20:30:07.657615] Test:  [ 80/196]  eta: 0:00:52  loss: 3.5115 (3.5310)  acc1: 28.1250 (28.1057)  acc5: 50.0000 (54.5139)  time: 0.4219  data: 0.0011  max mem: 64199
[20:30:11.907931] Test:  [ 90/196]  eta: 0:00:47  loss: 3.5881 (3.5349)  acc1: 26.5625 (27.9018)  acc5: 51.5625 (54.4815)  time: 0.4223  data: 0.0029  max mem: 64199
[20:30:16.122259] Test:  [100/196]  eta: 0:00:42  loss: 3.5812 (3.5349)  acc1: 26.5625 (27.6764)  acc5: 54.6875 (54.5792)  time: 0.4232  data: 0.0039  max mem: 64199
[20:30:20.334011] Test:  [110/196]  eta: 0:00:38  loss: 3.4573 (3.5340)  acc1: 29.6875 (27.7872)  acc5: 54.6875 (54.5608)  time: 0.4212  data: 0.0021  max mem: 64199
[20:30:24.550534] Test:  [120/196]  eta: 0:00:33  loss: 3.5146 (3.5373)  acc1: 29.6875 (27.8151)  acc5: 54.6875 (54.5971)  time: 0.4203  data: 0.0011  max mem: 64199
[20:30:28.769210] Test:  [130/196]  eta: 0:00:29  loss: 3.5544 (3.5417)  acc1: 28.1250 (27.8626)  acc5: 53.1250 (54.5205)  time: 0.4207  data: 0.0011  max mem: 64199
[20:30:32.983062] Test:  [140/196]  eta: 0:00:24  loss: 3.5279 (3.5383)  acc1: 28.1250 (27.8923)  acc5: 54.6875 (54.6321)  time: 0.4216  data: 0.0011  max mem: 64199
[20:30:37.195082] Test:  [150/196]  eta: 0:00:20  loss: 3.5030 (3.5367)  acc1: 29.6875 (28.0008)  acc5: 54.6875 (54.6772)  time: 0.4212  data: 0.0008  max mem: 64199
[20:30:41.406333] Test:  [160/196]  eta: 0:00:15  loss: 3.5269 (3.5387)  acc1: 28.1250 (27.9503)  acc5: 54.6875 (54.6584)  time: 0.4203  data: 0.0008  max mem: 64199
[20:30:45.611851] Test:  [170/196]  eta: 0:00:11  loss: 3.5379 (3.5406)  acc1: 26.5625 (27.7961)  acc5: 53.1250 (54.5139)  time: 0.4200  data: 0.0001  max mem: 64199
[20:30:49.813351] Test:  [180/196]  eta: 0:00:06  loss: 3.4937 (3.5346)  acc1: 28.1250 (27.7970)  acc5: 54.6875 (54.7738)  time: 0.4203  data: 0.0002  max mem: 64199
[20:30:53.969511] Test:  [190/196]  eta: 0:00:02  loss: 3.4862 (3.5313)  acc1: 28.1250 (27.8305)  acc5: 57.8125 (54.9002)  time: 0.4178  data: 0.0001  max mem: 64199
[20:30:55.894981] Test:  [195/196]  eta: 0:00:00  loss: 3.4832 (3.5283)  acc1: 29.6875 (27.9360)  acc5: 56.2500 (54.9360)  time: 0.4079  data: 0.0001  max mem: 64199
[20:30:56.021626] Test: Total time: 0:01:24 (0.4335 s / it)
[20:30:56.022703] * Acc@1 28.348 Acc@5 54.614 loss 3.524
[20:30:56.022774] Accuracy of the network on the 50000 test images: 28.3%
[20:30:56.022789] Max accuracy: 28.35%
[20:30:56.028591] log_dir: /ibex/ai/project/c2090/lomar_plus_save/logs/raven448/finetuned_mae_encoderonly_mask_0.8_neigh_45_wind_7_num_4_epoches_100_r_448
[20:30:59.991255] Epoch: [1]  [   0/5004]  eta: 5:30:25  lr: 0.000400  loss: 4.9822 (4.9822)  time: 3.9619  data: 2.0434  max mem: 64199
[20:31:24.615471] Epoch: [1]  [  20/5004]  eta: 1:53:04  lr: 0.000402  loss: 5.4765 (5.4419)  time: 1.2312  data: 0.0001  max mem: 64199
[20:31:49.195186] Epoch: [1]  [  40/5004]  eta: 1:47:16  lr: 0.000403  loss: 5.5983 (5.5003)  time: 1.2289  data: 0.0002  max mem: 64199
[20:32:13.782723] Epoch: [1]  [  60/5004]  eta: 1:45:01  lr: 0.000405  loss: 5.6109 (5.5163)  time: 1.2293  data: 0.0002  max mem: 64199
[20:32:38.375488] Epoch: [1]  [  80/5004]  eta: 1:43:41  lr: 0.000406  loss: 5.6811 (5.5590)  time: 1.2296  data: 0.0002  max mem: 64199
[20:33:02.943198] Epoch: [1]  [ 100/5004]  eta: 1:42:42  lr: 0.000408  loss: 5.6191 (5.5555)  time: 1.2283  data: 0.0002  max mem: 64199
[20:33:27.481887] Epoch: [1]  [ 120/5004]  eta: 1:41:52  lr: 0.000410  loss: 5.6186 (5.5588)  time: 1.2269  data: 0.0002  max mem: 64199
[20:33:52.061645] Epoch: [1]  [ 140/5004]  eta: 1:41:12  lr: 0.000411  loss: 5.5667 (5.5482)  time: 1.2289  data: 0.0001  max mem: 64199
[20:34:16.641528] Epoch: [1]  [ 160/5004]  eta: 1:40:35  lr: 0.000413  loss: 5.7089 (5.5478)  time: 1.2289  data: 0.0002  max mem: 64199
[20:34:41.224392] Epoch: [1]  [ 180/5004]  eta: 1:40:01  lr: 0.000414  loss: 5.4005 (5.5314)  time: 1.2291  data: 0.0001  max mem: 64199
[20:35:05.786491] Epoch: [1]  [ 200/5004]  eta: 1:39:29  lr: 0.000416  loss: 5.4707 (5.5215)  time: 1.2281  data: 0.0001  max mem: 64199
[20:35:30.396555] Epoch: [1]  [ 220/5004]  eta: 1:38:59  lr: 0.000418  loss: 5.6108 (5.5266)  time: 1.2305  data: 0.0001  max mem: 64199
[20:35:54.936036] Epoch: [1]  [ 240/5004]  eta: 1:38:28  lr: 0.000419  loss: 5.6449 (5.5258)  time: 1.2269  data: 0.0001  max mem: 64199
[20:36:19.485118] Epoch: [1]  [ 260/5004]  eta: 1:37:59  lr: 0.000421  loss: 5.5533 (5.5306)  time: 1.2274  data: 0.0002  max mem: 64199
[20:36:44.070467] Epoch: [1]  [ 280/5004]  eta: 1:37:30  lr: 0.000422  loss: 5.4473 (5.5324)  time: 1.2292  data: 0.0001  max mem: 64199
